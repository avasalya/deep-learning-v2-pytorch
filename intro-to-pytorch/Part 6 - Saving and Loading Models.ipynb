{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.6.8 64-bit","language":"python","name":"python_defaultSpec_1596603855748"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Part 6 - Saving and Loading Models.ipynb","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"d3bb1aad025646548f4bf16cd014b419":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f03b141dc4754468949d8fa26d4677ad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30e9b0ec4ec64561953b7962f5d2c9da","IPY_MODEL_75a9ac8c25ef453ca483ef1b6af95ef8"]}},"f03b141dc4754468949d8fa26d4677ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30e9b0ec4ec64561953b7962f5d2c9da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3469bf6d586445fd9fc318f40472a7ed","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9cd1b348b60f4676b6695102f6e4b992"}},"75a9ac8c25ef453ca483ef1b6af95ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_096ad5c734454fc5bcfed51b4e262c62","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 26427392/? [00:20&lt;00:00, 11879284.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_911bdebe238541a69b8dc15d77921e2e"}},"3469bf6d586445fd9fc318f40472a7ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9cd1b348b60f4676b6695102f6e4b992":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"096ad5c734454fc5bcfed51b4e262c62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"911bdebe238541a69b8dc15d77921e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fe0f8c95b144db4bc6af235b492ca3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_269cd995b53a42f7b0c560c7a9e83082","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b8d672cd9b74dfaba1ad8d24826f98c","IPY_MODEL_f7138d7151844035869808d346c804ed"]}},"269cd995b53a42f7b0c560c7a9e83082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b8d672cd9b74dfaba1ad8d24826f98c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d2f7bc69063c49bb9f6c8e4090eefd8b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30769408702e4d7cb86cd809ca1ded1b"}},"f7138d7151844035869808d346c804ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b92cea549fce4cbcbf798fd26b84f55b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 91325.02it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fcf7c420bb141dea7fbec4d518065ea"}},"d2f7bc69063c49bb9f6c8e4090eefd8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30769408702e4d7cb86cd809ca1ded1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b92cea549fce4cbcbf798fd26b84f55b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7fcf7c420bb141dea7fbec4d518065ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3eeb9c12d4724d8f89fce0f28f9bfb4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_182dfcbb731046a3943028a07168a0ac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_be54f341e0fa456d9a35552eb4c92286","IPY_MODEL_281628a7c86543ecb047efaf32675a95"]}},"182dfcbb731046a3943028a07168a0ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be54f341e0fa456d9a35552eb4c92286":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2e77bc73cb784def82758ad212f21cb6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54efc734d566443aaaed87bfabb31305"}},"281628a7c86543ecb047efaf32675a95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e8c2e886d794bf398c29ba9fac3fd10","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4423680/? [00:17&lt;00:00, 1400408.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f8d95bc54844101bb103f38654a6a51"}},"2e77bc73cb784def82758ad212f21cb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54efc734d566443aaaed87bfabb31305":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e8c2e886d794bf398c29ba9fac3fd10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f8d95bc54844101bb103f38654a6a51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaabcdba57174af49bf8e5a66c8854ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f8c01be8cb443d788f6eaf4615e921b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_65d8a296791142218bdb4768ee6c1a4c","IPY_MODEL_f40ea7adad2a4e349f9fabd14289f859"]}},"6f8c01be8cb443d788f6eaf4615e921b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65d8a296791142218bdb4768ee6c1a4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_eeee91fc545c4d89aed7926bfa9be07b","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1cd3bb5821fe470db3a86a29c86c1cf0"}},"f40ea7adad2a4e349f9fabd14289f859":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9bcabf17d31474d8d54fa7961d57876","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/5148 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45ec519e63bb4319bcd8bd5137572b99"}},"eeee91fc545c4d89aed7926bfa9be07b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1cd3bb5821fe470db3a86a29c86c1cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9bcabf17d31474d8d54fa7961d57876":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"45ec519e63bb4319bcd8bd5137572b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"vetOCb82wlD8","colab_type":"text"},"source":["# Saving and Loading Models\n","\n","In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."]},{"cell_type":"markdown","metadata":{"id":"ZWYYC5sLyCsf","colab_type":"text"},"source":["# FC MODEL"]},{"cell_type":"code","metadata":{"id":"GIyK1Bvqxwbe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596600120116,"user_tz":-540,"elapsed":4001,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","\n","class Network(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n","        ''' Builds a feedforward network with arbitrary hidden layers.\n","        \n","            Arguments\n","            ---------\n","            input_size: integer, size of the input layer\n","            output_size: integer, size of the output layer\n","            hidden_layers: list of integers, the sizes of the hidden layers\n","        \n","        '''\n","        super().__init__()\n","        # Input to a hidden layer\n","        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n","        \n","        # Add a variable number of more hidden layers\n","        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n","        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n","        \n","        self.output = nn.Linear(hidden_layers[-1], output_size)\n","        \n","        self.dropout = nn.Dropout(p=drop_p)\n","        \n","    def forward(self, x):\n","        ''' Forward pass through the network, returns the output logits '''\n","        \n","        for each in self.hidden_layers:\n","            x = F.relu(each(x))\n","            x = self.dropout(x)\n","        x = self.output(x)\n","        \n","        return F.log_softmax(x, dim=1)\n","\n","\n","def validation(model, testloader, criterion):\n","    accuracy = 0\n","    test_loss = 0\n","    for images, labels in testloader:\n","\n","        images = images.resize_(images.size()[0], 784)\n","\n","        output = model.forward(images)\n","        test_loss += criterion(output, labels).item()\n","\n","        ## Calculating the accuracy \n","        # Model's output is log-softmax, take exponential to get the probabilities\n","        ps = torch.exp(output)\n","        # Class with highest probability is our predicted class, compare with true label\n","        equality = (labels.data == ps.max(1)[1])\n","        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n","        accuracy += equality.type_as(torch.FloatTensor()).mean()\n","\n","    return test_loss, accuracy\n","\n","\n","def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n","    \n","    steps = 0\n","    running_loss = 0\n","    for e in range(epochs):\n","        # Model in training mode, dropout is on\n","        model.train()\n","        for images, labels in trainloader:\n","            steps += 1\n","            \n","            # Flatten images into a 784 long vector\n","            images.resize_(images.size()[0], 784)\n","            \n","            optimizer.zero_grad()\n","            \n","            output = model.forward(images)\n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            running_loss += loss.item()\n","\n","            if steps % print_every == 0:\n","                # Model in inference mode, dropout is off\n","                model.eval()\n","                \n","                # Turn off gradients for validation, will speed up inference\n","                with torch.no_grad():\n","                    test_loss, accuracy = validation(model, testloader, criterion)\n","                \n","                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n","                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n","                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n","                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n","                \n","                running_loss = 0\n","                \n","                # Make sure dropout and grads are on for training\n","                model.train()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-fe736b54562d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}]},{"cell_type":"markdown","metadata":{"id":"x6n5Pgr8x-U7","colab_type":"text"},"source":["# helper"]},{"cell_type":"code","metadata":{"id":"K03JtHbZxPjw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596600123430,"user_tz":-540,"elapsed":863,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from torch import nn, optim\n","from torch.autograd import Variable\n","\n","\n","def test_network(net, trainloader):\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","    dataiter = iter(trainloader)\n","    images, labels = dataiter.next()\n","\n","    # Create Variables for the inputs and targets\n","    inputs = Variable(images)\n","    targets = Variable(images)\n","\n","    # Clear the gradients from all Variables\n","    optimizer.zero_grad()\n","\n","    # Forward pass, then backward pass, then update weights\n","    output = net.forward(inputs)\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    return True\n","\n","\n","def imshow(image, ax=None, title=None, normalize=True):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    if ax is None:\n","        fig, ax = plt.subplots()\n","    image = image.numpy().transpose((1, 2, 0))\n","\n","    if normalize:\n","        mean = np.array([0.485, 0.456, 0.406])\n","        std = np.array([0.229, 0.224, 0.225])\n","        image = std * image + mean\n","        image = np.clip(image, 0, 1)\n","\n","    ax.imshow(image)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    ax.tick_params(axis='both', length=0)\n","    ax.set_xticklabels('')\n","    ax.set_yticklabels('')\n","\n","    return ax\n","\n","\n","def view_recon(img, recon):\n","    ''' Function for displaying an image (as a PyTorch Tensor) and its\n","        reconstruction also a PyTorch Tensor\n","    '''\n","\n","    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n","    axes[0].imshow(img.numpy().squeeze())\n","    axes[1].imshow(recon.data.numpy().squeeze())\n","    for ax in axes:\n","        ax.axis('off')\n","        ax.set_adjustable('box-forced')\n","\n","def view_classify(img, ps, version=\"MNIST\"):\n","    ''' Function for viewing an image and it's predicted classes.\n","    '''\n","    ps = ps.data.numpy().squeeze()\n","\n","    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n","    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n","    ax1.axis('off')\n","    ax2.barh(np.arange(10), ps)\n","    ax2.set_aspect(0.1)\n","    ax2.set_yticks(np.arange(10))\n","    if version == \"MNIST\":\n","        ax2.set_yticklabels(np.arange(10))\n","    elif version == \"Fashion\":\n","        ax2.set_yticklabels(['T-shirt/top',\n","                            'Trouser',\n","                            'Pullover',\n","                            'Dress',\n","                            'Coat',\n","                            'Sandal',\n","                            'Shirt',\n","                            'Sneaker',\n","                            'Bag',\n","                            'Ankle Boot'], size='small');\n","    ax2.set_title('Class Probability')\n","    ax2.set_xlim(0, 1.1)\n","\n","    plt.tight_layout()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5xTcGkkwlD-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596601216745,"user_tz":-540,"elapsed":596,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"o74YYFYZwlEB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383,"referenced_widgets":["d3bb1aad025646548f4bf16cd014b419","f03b141dc4754468949d8fa26d4677ad","30e9b0ec4ec64561953b7962f5d2c9da","75a9ac8c25ef453ca483ef1b6af95ef8","3469bf6d586445fd9fc318f40472a7ed","9cd1b348b60f4676b6695102f6e4b992","096ad5c734454fc5bcfed51b4e262c62","911bdebe238541a69b8dc15d77921e2e","6fe0f8c95b144db4bc6af235b492ca3e","269cd995b53a42f7b0c560c7a9e83082","2b8d672cd9b74dfaba1ad8d24826f98c","f7138d7151844035869808d346c804ed","d2f7bc69063c49bb9f6c8e4090eefd8b","30769408702e4d7cb86cd809ca1ded1b","b92cea549fce4cbcbf798fd26b84f55b","7fcf7c420bb141dea7fbec4d518065ea","3eeb9c12d4724d8f89fce0f28f9bfb4c","182dfcbb731046a3943028a07168a0ac","be54f341e0fa456d9a35552eb4c92286","281628a7c86543ecb047efaf32675a95","2e77bc73cb784def82758ad212f21cb6","54efc734d566443aaaed87bfabb31305","2e8c2e886d794bf398c29ba9fac3fd10","9f8d95bc54844101bb103f38654a6a51","eaabcdba57174af49bf8e5a66c8854ba","6f8c01be8cb443d788f6eaf4615e921b","65d8a296791142218bdb4768ee6c1a4c","f40ea7adad2a4e349f9fabd14289f859","eeee91fc545c4d89aed7926bfa9be07b","1cd3bb5821fe470db3a86a29c86c1cf0","d9bcabf17d31474d8d54fa7961d57876","45ec519e63bb4319bcd8bd5137572b99"]},"executionInfo":{"status":"ok","timestamp":1596601223046,"user_tz":-540,"elapsed":4842,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"be9d9362-979a-4ab3-eda2-33d7b94e9f7b"},"source":["# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","# Download and load the training data\n","trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Download and load the test data\n","testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3bb1aad025646548f4bf16cd014b419","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fe0f8c95b144db4bc6af235b492ca3e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3eeb9c12d4724d8f89fce0f28f9bfb4c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eaabcdba57174af49bf8e5a66c8854ba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n","Processing...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"},{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cg1bs_fYwlED","colab_type":"text"},"source":["Here we can see one of the images."]},{"cell_type":"code","metadata":{"id":"J2i4cVuBwlEE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"ok","timestamp":1596601230273,"user_tz":-540,"elapsed":673,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"9abd4956-a4d9-419b-b2ec-91555f1b459d"},"source":["image, label = next(iter(trainloader))\n","imshow(image[0,:]);"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"image/png":{"width":231,"height":231},"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"rm9IpfdiwlEG","colab_type":"text"},"source":["# Train a network\n","\n","To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."]},{"cell_type":"code","metadata":{"id":"AdBS6VRTwlEI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596601272524,"user_tz":-540,"elapsed":611,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["# Create the network, define the criterion and optimizer\n","\n","model = Network(784, 10, [512, 256, 128])\n","criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjyKT_F3wlEL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":790},"executionInfo":{"status":"ok","timestamp":1596601394575,"user_tz":-540,"elapsed":120006,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"744d74bd-a360-455a-9732-27290592f152"},"source":["train(model, trainloader, testloader, criterion, optimizer, epochs=2)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch: 1/2..  Training Loss: 1.727..  Test Loss: 1.014..  Test Accuracy: 0.609\n","Epoch: 1/2..  Training Loss: 1.057..  Test Loss: 0.765..  Test Accuracy: 0.717\n","Epoch: 1/2..  Training Loss: 0.878..  Test Loss: 0.706..  Test Accuracy: 0.737\n","Epoch: 1/2..  Training Loss: 0.851..  Test Loss: 0.656..  Test Accuracy: 0.754\n","Epoch: 1/2..  Training Loss: 0.743..  Test Loss: 0.634..  Test Accuracy: 0.761\n","Epoch: 1/2..  Training Loss: 0.719..  Test Loss: 0.606..  Test Accuracy: 0.765\n","Epoch: 1/2..  Training Loss: 0.717..  Test Loss: 0.603..  Test Accuracy: 0.771\n","Epoch: 1/2..  Training Loss: 0.675..  Test Loss: 0.576..  Test Accuracy: 0.778\n","Epoch: 1/2..  Training Loss: 0.657..  Test Loss: 0.560..  Test Accuracy: 0.785\n","Epoch: 1/2..  Training Loss: 0.655..  Test Loss: 0.551..  Test Accuracy: 0.795\n","Epoch: 1/2..  Training Loss: 0.630..  Test Loss: 0.537..  Test Accuracy: 0.806\n","Epoch: 1/2..  Training Loss: 0.594..  Test Loss: 0.532..  Test Accuracy: 0.808\n","Epoch: 1/2..  Training Loss: 0.647..  Test Loss: 0.531..  Test Accuracy: 0.795\n","Epoch: 1/2..  Training Loss: 0.613..  Test Loss: 0.520..  Test Accuracy: 0.817\n","Epoch: 1/2..  Training Loss: 0.617..  Test Loss: 0.522..  Test Accuracy: 0.812\n","Epoch: 1/2..  Training Loss: 0.601..  Test Loss: 0.491..  Test Accuracy: 0.820\n","Epoch: 1/2..  Training Loss: 0.554..  Test Loss: 0.500..  Test Accuracy: 0.816\n","Epoch: 1/2..  Training Loss: 0.603..  Test Loss: 0.498..  Test Accuracy: 0.821\n","Epoch: 1/2..  Training Loss: 0.589..  Test Loss: 0.513..  Test Accuracy: 0.812\n","Epoch: 1/2..  Training Loss: 0.555..  Test Loss: 0.484..  Test Accuracy: 0.822\n","Epoch: 1/2..  Training Loss: 0.568..  Test Loss: 0.483..  Test Accuracy: 0.823\n","Epoch: 1/2..  Training Loss: 0.565..  Test Loss: 0.517..  Test Accuracy: 0.821\n","Epoch: 1/2..  Training Loss: 0.590..  Test Loss: 0.494..  Test Accuracy: 0.815\n","Epoch: 2/2..  Training Loss: 0.557..  Test Loss: 0.493..  Test Accuracy: 0.817\n","Epoch: 2/2..  Training Loss: 0.560..  Test Loss: 0.482..  Test Accuracy: 0.825\n","Epoch: 2/2..  Training Loss: 0.560..  Test Loss: 0.468..  Test Accuracy: 0.830\n","Epoch: 2/2..  Training Loss: 0.548..  Test Loss: 0.471..  Test Accuracy: 0.831\n","Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.470..  Test Accuracy: 0.825\n","Epoch: 2/2..  Training Loss: 0.543..  Test Loss: 0.459..  Test Accuracy: 0.833\n","Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.474..  Test Accuracy: 0.826\n","Epoch: 2/2..  Training Loss: 0.558..  Test Loss: 0.466..  Test Accuracy: 0.828\n","Epoch: 2/2..  Training Loss: 0.516..  Test Loss: 0.458..  Test Accuracy: 0.835\n","Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.467..  Test Accuracy: 0.833\n","Epoch: 2/2..  Training Loss: 0.563..  Test Loss: 0.478..  Test Accuracy: 0.823\n","Epoch: 2/2..  Training Loss: 0.556..  Test Loss: 0.476..  Test Accuracy: 0.825\n","Epoch: 2/2..  Training Loss: 0.567..  Test Loss: 0.478..  Test Accuracy: 0.828\n","Epoch: 2/2..  Training Loss: 0.546..  Test Loss: 0.485..  Test Accuracy: 0.822\n","Epoch: 2/2..  Training Loss: 0.530..  Test Loss: 0.460..  Test Accuracy: 0.833\n","Epoch: 2/2..  Training Loss: 0.548..  Test Loss: 0.458..  Test Accuracy: 0.834\n","Epoch: 2/2..  Training Loss: 0.509..  Test Loss: 0.448..  Test Accuracy: 0.838\n","Epoch: 2/2..  Training Loss: 0.504..  Test Loss: 0.466..  Test Accuracy: 0.831\n","Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.446..  Test Accuracy: 0.836\n","Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.442..  Test Accuracy: 0.840\n","Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.479..  Test Accuracy: 0.826\n","Epoch: 2/2..  Training Loss: 0.548..  Test Loss: 0.443..  Test Accuracy: 0.840\n","Epoch: 2/2..  Training Loss: 0.515..  Test Loss: 0.437..  Test Accuracy: 0.840\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6fcgu_ajwlEO","colab_type":"text"},"source":["## Saving and loading networks\n","\n","As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n","\n","The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers."]},{"cell_type":"code","metadata":{"id":"-IVMg--BwlEO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1596601400875,"user_tz":-540,"elapsed":614,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"2ae1c414-92fc-4c7a-93bd-0d3fa0ffa563"},"source":["print(\"Our model: \\n\\n\", model, '\\n')\n","print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Our model: \n","\n"," Network(\n","  (hidden_layers): ModuleList(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): Linear(in_features=512, out_features=256, bias=True)\n","    (2): Linear(in_features=256, out_features=128, bias=True)\n","  )\n","  (output): Linear(in_features=128, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xESU5SwqwlER","colab_type":"text"},"source":["The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`."]},{"cell_type":"code","metadata":{"id":"o8A854y1wlER","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596601434346,"user_tz":-540,"elapsed":617,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["torch.save(model.state_dict(), 'checkpoint.pth')"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sTuf7LrJwlET","colab_type":"text"},"source":["Then we can load the state dict with `torch.load`."]},{"cell_type":"code","metadata":{"id":"mi3Emf2dwlEU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596601436351,"user_tz":-540,"elapsed":920,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"789118f7-87c9-45f6-e3d8-6118bc247071"},"source":["state_dict = torch.load('checkpoint.pth')\n","print(state_dict.keys())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FMxc9UzewlEW","colab_type":"text"},"source":["And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`."]},{"cell_type":"code","metadata":{"id":"dIcTP6eAwlEW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596601453883,"user_tz":-540,"elapsed":637,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"1a8502bb-44de-4e16-e91b-f2fa703214a4"},"source":["model.load_state_dict(state_dict)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"-NSzj98bwlEY","colab_type":"text"},"source":["Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."]},{"cell_type":"code","metadata":{"id":"zdr1kSKawlEZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":481},"executionInfo":{"status":"error","timestamp":1596601511091,"user_tz":-540,"elapsed":632,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"9756a710-29f0-4191-9fd3-866061a27b2b"},"source":["# Try this\n","model = Network(784, 10, [400, 200, 100])\n","# This will throw an error because the tensor sizes are wrong!\n","model.load_state_dict(state_dict)"],"execution_count":14,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-796f2ae97f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."]}]},{"cell_type":"markdown","metadata":{"id":"zueAo-uBwlEc","colab_type":"text"},"source":["This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."]},{"cell_type":"code","metadata":{"id":"Mi816rLNwlEc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596601577202,"user_tz":-540,"elapsed":983,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["checkpoint = {'input_size': 784,\n","              'output_size': 10,\n","              'hidden_layers': [each.out_features for each in model.hidden_layers],\n","              'state_dict': model.state_dict()}\n","\n","torch.save(checkpoint, 'checkpoint.pth')"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVcb2m7wwlEg","colab_type":"text"},"source":["Now the checkpoint has all the necessary information to rebuild the trained model. You can easily make that a function if you want. Similarly, we can write a function to load checkpoints. "]},{"cell_type":"code","metadata":{"id":"-dbb-wzMwlEg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596601578390,"user_tz":-540,"elapsed":595,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}}},"source":["def load_checkpoint(filepath):\n","    checkpoint = torch.load(filepath)\n","    model = Network(checkpoint['input_size'],\n","                             checkpoint['output_size'],\n","                             checkpoint['hidden_layers'])\n","    model.load_state_dict(checkpoint['state_dict'])\n","    \n","    return model"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"t1cOOfUGwlEi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1596601580110,"user_tz":-540,"elapsed":603,"user":{"displayName":"Ashesh Vasalya","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBDAMhsbCpj1e1RvJpRTdj34MxLTSwcIwZWxgenw=s64","userId":"01681910271861283832"}},"outputId":"78fdd9f9-e555-4259-bbd7-dd3a843833bb"},"source":["model = load_checkpoint('checkpoint.pth')\n","print(model)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Network(\n","  (hidden_layers): ModuleList(\n","    (0): Linear(in_features=784, out_features=400, bias=True)\n","    (1): Linear(in_features=400, out_features=200, bias=True)\n","    (2): Linear(in_features=200, out_features=100, bias=True)\n","  )\n","  (output): Linear(in_features=100, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")\n"],"name":"stdout"}]}]}